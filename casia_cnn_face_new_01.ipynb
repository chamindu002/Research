{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 4321504,
          "sourceType": "datasetVersion",
          "datasetId": 2545087
        }
      ],
      "dockerImageVersionId": 31236,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "casia_cnn_face_new_01",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chamindu002/Research/blob/main/casia_cnn_face_new_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "nhatdealin_casiawebface_dataset_crop_path = kagglehub.dataset_download('nhatdealin/casiawebface-dataset-crop')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "-HEg6lZ_mMa_"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "# Install timm for models and huggingface_hub for cloud saving\n",
        "!pip install timm huggingface_hub"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:52:21.128753Z",
          "iopub.execute_input": "2026-01-07T17:52:21.129Z",
          "iopub.status.idle": "2026-01-07T17:52:28.891743Z",
          "shell.execute_reply.started": "2026-01-07T17:52:21.128975Z",
          "shell.execute_reply": "2026-01-07T17:52:28.891028Z"
        },
        "id": "Jc_rPyydmMbE",
        "outputId": "cac2ca0f-28d0-436e-bab7-a024ebb2e79e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\nRequirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.11.12)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports and Device Setup\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "from huggingface_hub import HfApi, login\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Device Config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"‚úÖ Device set to: {device}\")\n",
        "\n",
        "# Check CUDA details\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# --- SECURE HUGGING FACE LOGIN ---\n",
        "try:\n",
        "    user_secrets = UserSecretsClient()\n",
        "    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
        "    login(token=hf_token)\n",
        "    print(\"‚úÖ Logged in to Hugging Face Hub securely.\")\n",
        "    USE_HF_BACKUP = True\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Cloud Backup disabled. Could not find 'HF_TOKEN' in Kaggle Secrets.\")\n",
        "    print(\"   (To enable: Add-ons -> Secrets -> Add 'HF_TOKEN')\")\n",
        "    USE_HF_BACKUP = False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:52:28.89324Z",
          "iopub.execute_input": "2026-01-07T17:52:28.893522Z",
          "iopub.status.idle": "2026-01-07T17:52:41.117453Z",
          "shell.execute_reply.started": "2026-01-07T17:52:28.893495Z",
          "shell.execute_reply": "2026-01-07T17:52:41.116817Z"
        },
        "id": "cMIYFZl-mMbH",
        "outputId": "1deb61cd-72e1-48ec-9349-a97aa99f2bbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "‚úÖ Device set to: cuda\n   GPU: Tesla T4\n   Memory: 15.83 GB\n‚úÖ Logged in to Hugging Face Hub securely.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Enhanced Configuration\n",
        "class Config:\n",
        "    # Dataset Path\n",
        "    DATA_DIR = '/kaggle/input/casiawebface-dataset-crop/CASIA-WebFace_crop'\n",
        "\n",
        "    # Model Architecture\n",
        "    MODEL_NAME = 'efficientnet_b0'  # Can upgrade to 'efficientnet_b3' if GPU allows\n",
        "    IMG_SIZE = 224\n",
        "    EMBEDDING_SIZE = 512  # Feature embedding dimension\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    BATCH_SIZE = 64  # Increased from 32 for more stable gradients\n",
        "    EPOCHS = 50  # Increased for better convergence\n",
        "    LEARNING_RATE = 1e-4  # Reduced from 3e-4 for fine-tuning\n",
        "    BACKBONE_LR = 5e-5  # Lower LR for pretrained backbone\n",
        "    NUM_WORKERS = 2\n",
        "\n",
        "    # Regularization\n",
        "    WEIGHT_DECAY = 1e-4  # Reduced from 1e-3\n",
        "    DROPOUT = 0.3  # Reduced from 0.5\n",
        "    LABEL_SMOOTHING = 0.1\n",
        "    MIN_SAMPLES = 3\n",
        "\n",
        "    # Early Stopping\n",
        "    PATIENCE = 10  # Stop if no improvement for 10 epochs\n",
        "    MIN_DELTA = 0.001  # Minimum improvement to count\n",
        "\n",
        "    # Augmentation\n",
        "    MIXUP_ALPHA = 0.2  # Mixup augmentation strength\n",
        "    USE_MIXUP = True\n",
        "\n",
        "    # Cloud Backup\n",
        "    HF_REPO_ID = \"chami002/casia-face-recognition\"\n",
        "    MODEL_FILENAME = \"best_face_model.pth\"\n",
        "\n",
        "    # Logging\n",
        "    SAVE_FREQ = 5  # Save checkpoint every N epochs\n",
        "\n",
        "cfg = Config()\n",
        "print(\"‚úÖ Enhanced Configuration loaded\")\n",
        "print(f\"   Model: {cfg.MODEL_NAME}\")\n",
        "print(f\"   Batch Size: {cfg.BATCH_SIZE}\")\n",
        "print(f\"   Learning Rate: {cfg.LEARNING_RATE}\")\n",
        "print(f\"   Epochs: {cfg.EPOCHS}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:52:41.118286Z",
          "iopub.execute_input": "2026-01-07T17:52:41.118774Z",
          "iopub.status.idle": "2026-01-07T17:52:41.124756Z",
          "shell.execute_reply.started": "2026-01-07T17:52:41.118751Z",
          "shell.execute_reply": "2026-01-07T17:52:41.124126Z"
        },
        "id": "cICM44FkmMbI",
        "outputId": "9e12c018-c1a7-40c5-ff60-4e8986828a4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Enhanced Configuration loaded\n   Model: efficientnet_b0\n   Batch Size: 64\n   Learning Rate: 0.0001\n   Epochs: 50\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Data Preparation"
      ],
      "metadata": {
        "id": "pVa1CI51mMbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Data Preparation with Enhanced Analysis\n",
        "def prepare_metadata(data_dir):\n",
        "    print(f\"üìÇ Scanning files in {data_dir}...\")\n",
        "\n",
        "    # Grab all jpg/png files\n",
        "    files = glob.glob(os.path.join(data_dir, \"**/*.jpg\"), recursive=True) + \\\n",
        "            glob.glob(os.path.join(data_dir, \"**/*.png\"), recursive=True) + \\\n",
        "            glob.glob(os.path.join(data_dir, \"*.jpg\")) + \\\n",
        "            glob.glob(os.path.join(data_dir, \"*.png\"))\n",
        "\n",
        "    if not files:\n",
        "        raise ValueError(\"‚ùå No images found! Check your cfg.DATA_DIR path.\")\n",
        "\n",
        "    print(f\"   Found {len(files)} total files\")\n",
        "\n",
        "    # Parse filenames: \"00000045_001.jpg\" -> ID: \"00000045\"\n",
        "    data = []\n",
        "    for f in tqdm(files, desc=\"Parsing files\"):\n",
        "        filename = os.path.basename(f)\n",
        "        try:\n",
        "            # Extract ID (everything before the first underscore)\n",
        "            person_id = filename.split('_')[0]\n",
        "            data.append({'filepath': f, 'label': person_id})\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Analyze class distribution\n",
        "    counts = df['label'].value_counts()\n",
        "    print(f\"\\nüìä Dataset Statistics:\")\n",
        "    print(f\"   Total Images: {len(df)}\")\n",
        "    print(f\"   Unique Identities: {len(counts)}\")\n",
        "    print(f\"   Avg images per person: {counts.mean():.1f}\")\n",
        "    print(f\"   Min images per person: {counts.min()}\")\n",
        "    print(f\"   Max images per person: {counts.max()}\")\n",
        "\n",
        "    # Filter out identities with too few images\n",
        "    valid_labels = counts[counts >= cfg.MIN_SAMPLES].index\n",
        "    df_clean = df[df['label'].isin(valid_labels)].copy()\n",
        "\n",
        "    removed = len(df) - len(df_clean)\n",
        "    print(f\"\\nüßπ Filtered out {removed} images from identities with < {cfg.MIN_SAMPLES} samples\")\n",
        "    print(f\"   Final Dataset: {len(df_clean)} images\")\n",
        "    print(f\"   Final Identities: {df_clean['label'].nunique()}\")\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# Run preparation\n",
        "df = prepare_metadata(cfg.DATA_DIR)\n",
        "\n",
        "# Encode Labels (String ID -> 0, 1, 2, ...)\n",
        "label_encoder = LabelEncoder()\n",
        "df['label_idx'] = label_encoder.fit_transform(df['label'])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "print(f\"\\n‚úÖ Data preparation complete\")\n",
        "print(f\"   Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:52:41.126248Z",
          "iopub.execute_input": "2026-01-07T17:52:41.126521Z",
          "iopub.status.idle": "2026-01-07T17:53:56.931231Z",
          "shell.execute_reply.started": "2026-01-07T17:52:41.126493Z",
          "shell.execute_reply": "2026-01-07T17:53:56.929757Z"
        },
        "id": "d7nfizUVmMbL",
        "outputId": "27ad38ff-bca0-4738-f84e-20f188c5f761"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üìÇ Scanning files in /kaggle/input/casiawebface-dataset-crop/CASIA-WebFace_crop...\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_55/451708238.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Run preparation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Encode Labels (String ID -> 0, 1, 2, ...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_55/451708238.py\u001b[0m in \u001b[0;36mprepare_metadata\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Grab all jpg/png files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"**/*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"**/*.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, root_dir, dir_fd, recursive, include_hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     return list(iglob(pathname, root_dir=root_dir, dir_fd=dir_fd, recursive=recursive,\n\u001b[0m\u001b[1;32m     29\u001b[0m                       include_hidden=include_hidden))\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, root_dir, dir_fd, recursive, dironly, include_hidden)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         for name in glob_in_dir(_join(root_dir, dirname), basename, dir_fd, dironly,\n\u001b[1;32m     98\u001b[0m                                include_hidden=include_hidden):\n",
            "\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, root_dir, dir_fd, recursive, dironly, include_hidden)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         for name in glob_in_dir(_join(root_dir, dirname), basename, dir_fd, dironly,\n\u001b[0m\u001b[1;32m     98\u001b[0m                                include_hidden=include_hidden):\n\u001b[1;32m     99\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36m_glob2\u001b[0;34m(dirname, pattern, dir_fd, dironly, include_hidden)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_isdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     yield from _rlistdir(dirname, dir_fd, dironly,\n\u001b[0m\u001b[1;32m    138\u001b[0m                          include_hidden=include_hidden)\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36m_rlistdir\u001b[0;34m(dirname, dir_fd, dironly, include_hidden)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m# Recursively yields relative pathnames inside a literal directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_rlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_listdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_hidden\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36m_listdir\u001b[0;34m(dirname, dir_fd, dironly)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_listdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m# Recursively yields relative pathnames inside a literal directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36m_iterdir\u001b[0;34m(dirname, dir_fd, dironly)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdironly\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mfsencode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                                 \u001b[0;32myield\u001b[0m \u001b[0mfsencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Train-Val Split"
      ],
      "metadata": {
        "id": "y8qxXUOcmMbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Stratified Train-Val Split\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.15,\n",
        "    stratify=df['label_idx'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"üìä Dataset Split:\")\n",
        "print(f\"   Train Set: {len(train_df)} images ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"   Val Set:   {len(val_df)} images ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"   Train classes: {train_df['label_idx'].nunique()}\")\n",
        "print(f\"   Val classes:   {val_df['label_idx'].nunique()}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.931726Z",
          "iopub.status.idle": "2026-01-07T17:53:56.931941Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.931836Z",
          "shell.execute_reply": "2026-01-07T17:53:56.931848Z"
        },
        "id": "na4kBbzfmMbN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Custom Dataset with Mixup"
      ],
      "metadata": {
        "id": "UrOzwDQVmMbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Enhanced Dataset Class\n",
        "class CasiaDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['filepath']\n",
        "        label = row['label_idx']\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            # Fallback to next image if corrupt\n",
        "            print(f\"‚ö†Ô∏è Corrupt image: {img_path}\")\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Mixup Augmentation Function\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    \"\"\"Apply mixup augmentation\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    \"\"\"Calculate mixup loss\"\"\"\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "print(\"‚úÖ Dataset class and Mixup functions defined\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.933111Z",
          "iopub.status.idle": "2026-01-07T17:53:56.933396Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.933269Z",
          "shell.execute_reply": "2026-01-07T17:53:56.933289Z"
        },
        "id": "BN40djl-mMbN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Enhanced Augmentation"
      ],
      "metadata": {
        "id": "WvhodOe7mMbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Enhanced Augmentation Pipeline\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((cfg.IMG_SIZE + 32, cfg.IMG_SIZE + 32)),  # Resize larger first\n",
        "    transforms.RandomCrop(cfg.IMG_SIZE),  # Then random crop\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.1),  # NEW: Random grayscale\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.1),  # NEW: Blur\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2))  # Increased probability\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create Datasets\n",
        "train_ds = CasiaDataset(train_df, transform=train_transforms)\n",
        "val_ds = CasiaDataset(val_df, transform=val_transforms)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=cfg.BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=cfg.NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    drop_last=True  # Drop incomplete batches for stability\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=cfg.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=cfg.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Data loaders created\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.934365Z",
          "iopub.status.idle": "2026-01-07T17:53:56.934603Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.934494Z",
          "shell.execute_reply": "2026-01-07T17:53:56.934507Z"
        },
        "id": "qtJc25dXmMbO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8: Enhanced Model Architecture"
      ],
      "metadata": {
        "id": "L2VDnR0TmMbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Enhanced Model Architecture\n",
        "class ImprovedFaceRecognitionModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes, embedding_size=512, dropout=0.3):\n",
        "        super(ImprovedFaceRecognitionModel, self).__init__()\n",
        "\n",
        "        # Load pretrained backbone\n",
        "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
        "        in_features = self.backbone.num_features\n",
        "\n",
        "        # Enhanced classifier head with batch normalization\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features, embedding_size),\n",
        "            nn.BatchNorm1d(embedding_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embedding_size, embedding_size // 2),\n",
        "            nn.BatchNorm1d(embedding_size // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout / 2),\n",
        "            nn.Linear(embedding_size // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # L2 normalization layer (optional, helps with face recognition)\n",
        "        self.use_l2_norm = False  # Set to True for normalized embeddings\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        if self.use_l2_norm:\n",
        "            features = F.normalize(features, p=2, dim=1)\n",
        "\n",
        "        output = self.classifier(features)\n",
        "        return output\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        \"\"\"Extract features for similarity comparison\"\"\"\n",
        "        with torch.no_grad():\n",
        "            features = self.backbone(x)\n",
        "            if self.use_l2_norm:\n",
        "                features = F.normalize(features, p=2, dim=1)\n",
        "        return features\n",
        "\n",
        "# Create model\n",
        "print(f\"üèóÔ∏è Building {cfg.MODEL_NAME} model...\")\n",
        "model = ImprovedFaceRecognitionModel(\n",
        "    model_name=cfg.MODEL_NAME,\n",
        "    num_classes=num_classes,\n",
        "    embedding_size=cfg.EMBEDDING_SIZE,\n",
        "    dropout=cfg.DROPOUT\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"‚úÖ Model created successfully\")\n",
        "print(f\"   Total parameters: {total_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.935591Z",
          "iopub.status.idle": "2026-01-07T17:53:56.935974Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.935775Z",
          "shell.execute_reply": "2026-01-07T17:53:56.935796Z"
        },
        "id": "vmaL9WJhmMbP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9: Optimizer and Scheduler"
      ],
      "metadata": {
        "id": "KADflPMnmMbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Optimizer, Loss, and Learning Rate Scheduler\n",
        "# Label Smoothing Loss\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=cfg.LABEL_SMOOTHING)\n",
        "\n",
        "# Differential Learning Rates (lower for backbone, higher for classifier)\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': model.backbone.parameters(), 'lr': cfg.BACKBONE_LR},\n",
        "    {'params': model.classifier.parameters(), 'lr': cfg.LEARNING_RATE}\n",
        "], weight_decay=cfg.WEIGHT_DECAY)\n",
        "\n",
        "# Cosine Annealing with Warm Restarts\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer,\n",
        "    T_0=10,  # Restart every 10 epochs\n",
        "    T_mult=2,  # Double the period after each restart\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "# Alternative: OneCycleLR (uncomment to use)\n",
        "# scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "#     optimizer,\n",
        "#     max_lr=[cfg.BACKBONE_LR * 10, cfg.LEARNING_RATE * 10],\n",
        "#     epochs=cfg.EPOCHS,\n",
        "#     steps_per_epoch=len(train_loader),\n",
        "#     pct_start=0.3\n",
        "# )\n",
        "\n",
        "print(\"‚úÖ Optimizer and scheduler configured\")\n",
        "print(f\"   Backbone LR: {cfg.BACKBONE_LR}\")\n",
        "print(f\"   Classifier LR: {cfg.LEARNING_RATE}\")\n",
        "print(f\"   Weight Decay: {cfg.WEIGHT_DECAY}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.937091Z",
          "iopub.status.idle": "2026-01-07T17:53:56.937406Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.937282Z",
          "shell.execute_reply": "2026-01-07T17:53:56.937301Z"
        },
        "id": "QK_DUwQimMbP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10: Enhanced Training Function"
      ],
      "metadata": {
        "id": "AYeQH556mMbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Enhanced Training Function with Mixup\n",
        "def train_fn(model, loader, optimizer, criterion, use_mixup=True):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    loop = tqdm(loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for imgs, labels in loop:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        # Apply mixup augmentation\n",
        "        if use_mixup and cfg.USE_MIXUP:\n",
        "            imgs, labels_a, labels_b, lam = mixup_data(imgs, labels, cfg.MIXUP_ALPHA)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
        "\n",
        "            # For accuracy calculation, use original labels\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (lam * preds.eq(labels_a).sum().item() +\n",
        "                       (1 - lam) * preds.eq(labels_b).sum().item())\n",
        "        else:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        loop.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
        "\n",
        "    return running_loss / len(loader), 100. * correct / total\n",
        "\n",
        "def val_fn(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    top5_correct = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loop = tqdm(loader, desc=\"Validation\", leave=False)\n",
        "        for imgs, labels in loop:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Top-1 accuracy\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "\n",
        "            # Top-5 accuracy\n",
        "            _, top5_preds = outputs.topk(5, dim=1)\n",
        "            top5_correct += sum([1 for i, label in enumerate(labels)\n",
        "                                if label in top5_preds[i]])\n",
        "\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            loop.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
        "\n",
        "    top1_acc = 100. * correct / total\n",
        "    top5_acc = 100. * top5_correct / total\n",
        "\n",
        "    return running_loss / len(loader), top1_acc, top5_acc, all_preds, all_labels\n",
        "\n",
        "print(\"‚úÖ Training and validation functions defined\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.938468Z",
          "iopub.status.idle": "2026-01-07T17:53:56.938794Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.938625Z",
          "shell.execute_reply": "2026-01-07T17:53:56.938642Z"
        },
        "id": "f_kqeO8YmMbQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 11: Early Stopping Class"
      ],
      "metadata": {
        "id": "9bWcJcwumMbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Early Stopping Implementation\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=0.001, mode='max'):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.mode = mode\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, score):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'max':\n",
        "            if score > self.best_score + self.min_delta:\n",
        "                self.best_score = score\n",
        "                self.counter = 0\n",
        "            else:\n",
        "                self.counter += 1\n",
        "        else:  # min mode\n",
        "            if score < self.best_score - self.min_delta:\n",
        "                self.best_score = score\n",
        "                self.counter = 0\n",
        "            else:\n",
        "                self.counter += 1\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "# Initialize early stopping\n",
        "early_stopping = EarlyStopping(patience=cfg.PATIENCE, min_delta=cfg.MIN_DELTA, mode='max')\n",
        "\n",
        "print(\"‚úÖ Early stopping initialized\")\n",
        "print(f\"   Patience: {cfg.PATIENCE} epochs\")\n",
        "print(f\"   Min improvement: {cfg.MIN_DELTA}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.939998Z",
          "iopub.status.idle": "2026-01-07T17:53:56.940347Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.940152Z",
          "shell.execute_reply": "2026-01-07T17:53:56.94017Z"
        },
        "id": "ATVYbNwZmMbQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Main Training Loop with All Enhancements\n",
        "# Setup Cloud Repo\n",
        "if USE_HF_BACKUP:\n",
        "    api = HfApi()\n",
        "    try:\n",
        "        api.create_repo(repo_id=cfg.HF_REPO_ID, repo_type=\"model\", exist_ok=True)\n",
        "        print(f\"‚úÖ Cloud Repository Ready: https://huggingface.co/{cfg.HF_REPO_ID}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Repo creation warning: {e}\")\n",
        "\n",
        "# Training History\n",
        "history = {\n",
        "    'train_loss': [], 'val_loss': [],\n",
        "    'train_acc': [], 'val_acc': [],\n",
        "    'top5_acc': [], 'learning_rates': []\n",
        "}\n",
        "\n",
        "best_acc = 0.0\n",
        "best_top5_acc = 0.0\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"üöÄ STARTING TRAINING\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Model: {cfg.MODEL_NAME}\")\n",
        "print(f\"Classes: {num_classes}\")\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "print(f\"Epochs: {cfg.EPOCHS}\")\n",
        "print(f\"Batch size: {cfg.BATCH_SIZE}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for epoch in range(cfg.EPOCHS):\n",
        "    print(f\"\\nüìÖ Epoch {epoch+1}/{cfg.EPOCHS}\")\n",
        "    print(f\"{'‚îÄ'*60}\")\n",
        "\n",
        "    # Get current learning rate\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Training phase\n",
        "    train_loss, train_acc = train_fn(\n",
        "        model, train_loader, optimizer, criterion,\n",
        "        use_mixup=(epoch < cfg.EPOCHS * 0.8)  # Disable mixup in last 20% of training\n",
        "    )\n",
        "\n",
        "    # Validation phase\n",
        "    val_loss, val_acc, top5_acc, val_preds, val_labels = val_fn(\n",
        "        model, val_loader, criterion\n",
        "    )\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Store history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['top5_acc'].append(top5_acc)\n",
        "    history['learning_rates'].append(current_lr)\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"üìä Results:\")\n",
        "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
        "    print(f\"   Top-5 Acc:  {top5_acc:.2f}%\")\n",
        "    print(f\"   Learning Rate: {current_lr:.6f}\")\n",
        "\n",
        "    # Calculate overfitting gap\n",
        "    gap = train_acc - val_acc\n",
        "    print(f\"   Overfit Gap: {gap:.2f}%\", end=\"\")\n",
        "    if gap > 20:\n",
        "        print(\" ‚ö†Ô∏è High overfitting!\")\n",
        "    elif gap > 10:\n",
        "        print(\" ‚ö†Ô∏è Moderate overfitting\")\n",
        "    else:\n",
        "        print(\" ‚úÖ Good generalization\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        improvement = val_acc - best_acc\n",
        "        best_acc = val_acc\n",
        "        best_top5_acc = top5_acc\n",
        "\n",
        "        # Save locally\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "            'best_top5_acc': best_top5_acc,\n",
        "            'num_classes': num_classes,\n",
        "            'label_encoder': label_encoder\n",
        "        }\n",
        "        torch.save(checkpoint, cfg.MODEL_FILENAME)\n",
        "        print(f\"   üíæ Saved Best Model (‚Üë{improvement:.2f}%)\")\n",
        "\n",
        "        # Upload to cloud\n",
        "        if USE_HF_BACKUP:\n",
        "            try:\n",
        "                print(\"   ‚òÅÔ∏è Uploading to Hugging Face...\", end=\"\")\n",
        "                api.upload_file(\n",
        "                    path_or_fileobj=cfg.MODEL_FILENAME,\n",
        "                    path_in_repo=cfg.MODEL_FILENAME,\n",
        "                    repo_id=cfg.HF_REPO_ID,\n",
        "                    repo_type=\"model\"\n",
        "                )\n",
        "                print(\" Done! ‚úÖ\")\n",
        "            except Exception as e:\n",
        "                print(f\" Failed ‚ùå ({e})\")\n",
        "\n",
        "    # Periodic checkpoint\n",
        "    if (epoch + 1) % cfg.SAVE_FREQ == 0:\n",
        "        checkpoint_name = f\"checkpoint_epoch_{epoch+1}.pth\"\n",
        "        torch.save(checkpoint, checkpoint_name)\n",
        "        print(f\"   üíæ Checkpoint saved: {checkpoint_name}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if early_stopping(val_acc):\n",
        "        print(f\"\\n‚èπÔ∏è Early stopping triggered at epoch {epoch+1}\")\n",
        "        print(f\"   No improvement for {cfg.PATIENCE} consecutive epochs\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úÖ TRAINING COMPLETE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Best Validation Accuracy: {best_acc:.2f}%\")\n",
        "print(f\"Best Top-5 Accuracy: {best_top5_acc:.2f}%\")\n",
        "print(f\"Final Overfitting Gap: {history['train_acc'][-1] - history['val_acc'][-1]:.2f}%\")\n",
        "print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.941355Z",
          "iopub.status.idle": "2026-01-07T17:53:56.941604Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.941482Z",
          "shell.execute_reply": "2026-01-07T17:53:56.941499Z"
        },
        "id": "ORbNED_5mMbR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "vizualization"
      ],
      "metadata": {
        "id": "rGyqdDsUmMbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "plt.plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
        "plt.title('Accuracy Improvement')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "plt.plot(history['val_loss'], label='Validation Loss', marker='o')\n",
        "plt.title('Loss Reduction')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-07T17:53:56.942989Z",
          "iopub.status.idle": "2026-01-07T17:53:56.943792Z",
          "shell.execute_reply.started": "2026-01-07T17:53:56.943606Z",
          "shell.execute_reply": "2026-01-07T17:53:56.943629Z"
        },
        "id": "DDhYPMtemMbR"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}